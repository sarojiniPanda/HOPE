---
title:  "Past Projects"
date:   2017-03-24 00:00:00
categories: [past-projects]
tags: [past-projects]
---
In this post, I will outline some past research projects.

Some of these projects appear on my CV, which can be accessed [here]({filename}/pdfs/CV.pdf).

## Connectome Project 
### _Final Project for CSCI 2420: Probabilistic Graphical Models_ (with Ivana Petrovic and Guangyao Zhou)

Neuron-to-neuron communication operates electrochemically, and neuronal signals are well-known to generally be followed by cellular influx of calcium ions into the associated pre-synaptic cell. Calcium-sensitive fluorescent indicators are often used in experimental settings to simultaneously monitor the activity of tens of thousands of neighboring neurons.  

The downloaded [data](http://www.kaggle.com/c/connectomics) includes time series of neural activity visualized with fluorescent indicators in a neuronal culture of $N = 100$ neurons, collected over a time period lasting one hour, at a sampling rate of $(\Delta t)^{−1} = 50$ Hz.  Based on this data, our goal was to infer directed connections between neurons in the network.

We made use of a nonlinear state space model, where the observed random variables at time $t
\Delta t$ are the corresponding fluorescence levels of the $N$
neurons.  The corresponding hidden random variables are the number of spikes for each neuron in the time interval $[ ( t - 1) \Delta t, t \Delta t]$, along with the calcium concentration in each neuron at time $t \Delta t$. 

We constructed a matrix which encodes the connectivity pattern between neurons; this is a hidden variable in our biologically-motivated, highly-detailed model (_... which we do not describe in full here_).  The connectivity matrix is built into the model through the assumption that a neuron is more likely to spike at time $t\Delta t$ if many of its pre-synaptic neurons fired at time $(t-1)\Delta t$.  Since this is a parameter estimation problem with incomplete observations, we used the expectation-maximization (EM) algorithm to solve for all unknown quantities.  We wrote the code entirely in Matlab.  Our final report can be found [here]({filename}/pdfs/2420_Final_Report.pdf).

## Patterns in Sign Language
### _Final Project for CLPS 1520: Computer Vision_

Recall that a __hidden Markov model (HMM)__ with observations $\{y_t\}_{t=1}^T$, latent states $\{z_t\}_{t=1}^T$, state-specific transition distributions $\{\pi_k\}_{k=1}^K$, emission distribution $F$, and emission parameters $\{\theta_k\}_{k=1}^K$ follows the following dynamics:
$$
z_t | z_{t-1} \sim \pi_{z_{t-1}}
$$
$$
y_t | z_t \sim F(\theta_{z_t})
$$

An __autoregressive hidden Markov model (ARHMM)__, in contrast, removes the modeling assumption that the observations are conditionally independent, given the latent state sequence.  For a school project, I persued the order-1 process, with lag matrices given by $\{A_k\}_{k=1}^K$, which evolved according to the following dynamics:
$$
z_t | z_{t-1} \sim \pi_{z_{t-1}}
$$
$$
y_t = A_{z_t}y_{t-1} + e_t(z_t)
$$

where $e_t(z_t) \sim \mathcal{N}(0, \Sigma_{z_t})$.  In this model, we see that each potential latent state specifies a linear dynamical system along which the observed data is permitted to evolve. 

For the final project in my course on computer vision, I fit an ARHMM on RGB-D recordings of sign language in order to see if it was possible to reliably detect motion patterns.  My idea was that this project could inspire new techniques for sign language translation, with detected latent states corresponding to higher-level vocabularies.  The code that I used to complete this project was written in Python by a colleague at Brown and can be found [here](https://bitbucket.org/michaelchughes/bnpy-dev/).

## Action Planning in iPOMDP Framework
### _Final Project for CSCI 2951-P: Learning and Sequential Decision Making_ (with Gabe Hope and Geng Ji)

Consider a robot that is trying to learn to play a simple computer game.  When it is his turn, the robot has a finite number of potential moves.  Once executed, the chosen move either increases or decreases the points in the game.  Say the robot has the goal of maximizing his score, and he has access to his point tally at all times.  We now introduce the mathematical framework that can be used to assist the robot in devising an optimal strategy to maximize his score.

A __Markov Decision Process (MDP)__ is a mathematical framework for modeling decision making.  It is formalized as a tuple $\{S, A, T, R, \gamma\}$, where:
- $S$ is a finite set of world states. 
    - _In the example above, this corresponds to a set of possible situations in the game for which the robot would have to decide his next move._
- $A$ is a finite set of actions.
    - _In the example above, this corresponds to the set of possible moves that the player could take._
- $T$ defines for all states $s,s' \in S$, actions $a \in A$, and times $t$, the probability that action $a$ in state $s$ at time $t$ results in state $s'$ at time $t+1$.
    - _In the example above, this corresponds to defining how the game screen is likely to change in response to different potential moves._
- $R$ defines for all states $s\in S$ and actions $a \in A$, the reward obtained by using action $a$ in state $s$.  We note that it is also possible to introduce some stochasticity here, where $R$ defines (for each $s \in S$, $a \in A$) a probability distribution on potential rewards. 
    - _In the example above, this corresponds to defining how different moves increase or decrease your score._
- $\gamma \in [0,1]$ is the discount factor, which controls the relative importance between current and future rewards.

At each time $t$, an agent acting in line with an MDP finds herself in some (observed) state $s_t \in S$.  She then takes some action $a_t \in A$ and transitions to a new (observed) state $s_{t+1}$, which is a draw from a categorical distribution with probabilities specified in $T$.  At the same time, she receives an immediate reward $r_t$, which is specified in $R$.  The agent has full _a priori_ knowledge of the states ($S$) and actions ($A$), but must learn $T$ and $R$ through experience.  As knowledge of the environment is gained, the agent is able to make better decisions towards her goal of maximizing discounted reward, defined as $\sum_{t=0}^\infty \gamma^t r_t$.

A __Partially Observable Markov Decision Process (POMDP)__ is a generalization of an MDP, wherein the agent cannot directly observe states.  In this case, the agent has _a priori_ knowledge of the number of states, but only receives a noisy estimate of which state she is in at any given time.  In this case, the agent must learn to infer the states that she has visited.

An __Infinite Partially Observable Markov Decision Process (iPOMDP)__ is a generalization of a POMDP, wherein the agent does not know the total number of states in the environment.  In this case, the agent must deduce the size of the set of world states.  It is worth noting that a nonparametric approach will be necessary, to permit the number of world states to potentially grow with time.

The set of unknowns of an agent acting in accordance with an iPOMDP makes this problem much more difficult to solve than the traditional MDP.  We re-implemented the results in one research paper for our final project.  Our final report can be found [here]({filename}/pdfs/2951_Final_Report.pdf).

## Clique Detection Beneath the Noise Floor
### Research Project at MIT Lincoln Laboratory (with Ben Miller)

Real-world graphs are naturally inhomogeneous and exhibit nonuniform edge densities within local substructures.  In this setting, it is often possible to break graphs into communities, or sets of vertices with a high number of within-group connections and fewer links between communities.  The problem of community detection in networks has become increasingly prevalent in recent years and has important applications to ﬁelds such as computer science, biology, and sociology. While community detection often considers partitioning a graph into multiple communities, a variant of the problem considers detection of a small subgraph with higher connectivity than the remainder of the graph, a special case of which is the planted clique problem. 

Recall that a clique is a set of vertices such that every two vertices are connected by an edge.  In the standard $(k, p, n)$ planted clique problem, one is given an Erdos-Renyi graph $G(n, p)$ with an embedded clique of size $k$, and the objective is to determine the hidden locations of the clique vertices. Formally, given the graph $G = (V, E)$, where $V$ is the set of vertices and $E$ is the set of edges (connections), with $|V | = n$, the desired outcome is the subset of vertices $V^* \subset V$, $|V^*| = k$ that belong to the clique.

In our procedure, instead of working directly with the edge set $E$, we will analyze the modularity matrix $B$ corresponding to our graph, which proves a useful representation of the graph’s topology.  It has been shown previously that thresholding the principal eigenvector of $B$ can yield the locations of the clique vertices.  However, this technique (and all PCA-based methods) for clique detection has a well-defined breakdown point, realized when the size of the clique is too small, relative to the density of the graph.

In this project at the MIT Lincoln Laboratory, we showed that DSPCA, a Matlab toolbox for sparse PCA, reliably pushes past the clique detection threshold for PCA.  Our final report can be found [here]({filename}/pdfs/MITLL_Paper.pdf).

## A Multiscale Model of Synergism in Cancer Therapy
### Research Project at the University of Michigan-Ann Arbor (with Dr. Trachette Jackson)

Since their approval for the treatment of cancer in the 1970s, platinum-based chemotherapeutic agents have been an essential part of the standard of care for lung, ovarian, colorectal, testicular, bladder and head and neck cancers. Cisplatin is the most commonly used platinum chemotherapeutic agent, but its efficacy is often compromised because of the substantial risk for severe toxicities.  For head and neck (HN) tumors, the sixth most common malignancy in the world, state-of-the-art treatment with anti-mitotic, platinum-based drugs, including cisplatin, still results in a 5-year disease-specific survival of approximately 60%.

In order to improve outcomes for HN cancers, a substantial amount of research is now focusing on the molecular biology of the tumors in an attempt to selectively target pathways involved in carcinogenesis.  Mounting evidence has demonstrated that the primarily intracellular, pro-survival proteins Bcl-2 and Bcl-xL, which are upregulated in a variety of tumor types, including HN, constitute unique and important therapeutic targets for cancer.

Researchers recently designed a new class of potent and specific, small-molecule dual inhibitors of Bcl-2 and Bcl-xL. Preliminary evidence suggests that BM-1197 is their most promising lead. It has been shown to be highly effective on HN cancer cells.  In order to exploit the therapeutic potential of BM-1197, and to predict optimal doses and dose scheduling, it is essential to combine biological experimentation, mathematical modeling, and numerical simulation to understand the molecular basis of their synergistic action.

We developed a simple, yet useful multilevel modeling framework to understand the mechanisms underlying the anti-tumor effect of therapeutic inhibition of Bcl-2 and Bcl-xL alone and in combination with cisplatin.

Specifically, we created a biologically-informed model composed of a system of ordinary differential equations.  The model captures cellular and intracellular dynamics, and we fit the model to experimental data through the use of ODE solvers in Matlab.  Our final paper can be found [here]({filename}/pdfs/Cancer_Paper.pdf).